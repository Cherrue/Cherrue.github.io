---

layout: single
title: \[기술도서\] 가상 면접 사례로 배우는 대규모 시스템 설계 기초
date: 2022-03-22 23:56:00 +0900
categories: engineering_boog high_availability
toc: true
toc_sticky: true
toc_label: Contents

---

# [기술도서] 가상 면접 사례로 배우는 대규모 시스템 설계 기초

Property: March 22, 2022 11:52 PM

시작일 : 2022-03-21

제목 : 가상 면접 사례로 배우는 대규모 시스템 설계 기초 (인사이트, 2021)

저자 : 알렉스 쉬

가격 : 21600원

경로 : 팀원 추천

# 1장 사용자 수에 따른 규모 확장성

## 1. 용어

- 스케일 업 : 수직 규모 확장. 장비 스펙 강화
- 스케일 아웃 : 수평 규모 확장. 장비 대수 증가
- SPOF : Single Point Of Failure. 특정 지점의 장애가 전체 서비스의 장애가 되는 포인트

## 2. 확장

가정 : 웹, 모바일 단말 대응 서버 어플리케이션

### 2-1. 단일서버 : 테스트, 소규모

모든 컴포넌트(웹, 앱, 데이터베이스, 캐시) 모두 서버 한 대에 구성

### 2-2. 데이터베이스 : 지속적인 사용자 발생

웹 계층과 데이터 계층 분리

RDB와 NoSQL 사용. 상황에 따라 다르지만 보통 혼합해서 쓴다.

NoSQL 고려사항

- low latency
- 비정형 데이터
- 파일이 아닌 API 서버
- 데이터의 양이 많은 경우

### 2-3. 웹 서버 규모 확장

스케일 업은 failover 대응이 불가능하고, 서버 비용이 비싸서 보통 스케일 아웃을 한다.

### 2-4. 로드밸런서

스케일 아웃 한 웹 서버에 부하를 고르게 분산하는 로드밸런서 설치

- 안정성 : 서버 failout 시 자동으로 연결을 끊음
- 확장성 : 반대로 서버가 추가되면 자동으로 연결

### 2-5. 데이터베이스 확장

보통 쓰기보다 읽기의 비중이 크기 때문에, 쓰기를 수행하는 주DB와 읽기를 수행하는 부DB 구성

- 성능 : 데이터 정합성을 위해 사본을 전달해야 해서 쓰기 성능이 떨어지나, 비중이 높은 읽기를 병렬로 처리해 성능이 좋아진다.
- 안정성 + 가용성 : 부DB가 죽으면 다른 부DB에 연결, 주DB가 죽으면 부DB 중 하나를 주DB로 변경

### 2-6. 캐시

데이터베이스의 읽기는 느리니, 속도가 빠른 캐시 서버에 둔다.

유의사항

- 데이터 갱신이 잦으면 사용 자제 : 캐시의 갱신은 DB 읽기와 같거나 느리다
- 휘발성 데이터만 저장 : 캐시는 서버 재시작 시 데이터 삭제
- 데이터 만료 기한 선정 : 짧으면 갱신이 잦아지고, 길면 불필요 데이터로 성능 하락
- 데이터 저장소와 캐시 저장소의 데이터 일관성 유지
- SPOF 회피 전략
- 캐시 메모리 크기 선정 : 크면 느리고 작으면 갱신이 잦아진다.
- eviction 정책 선정 : 저장 공간이 없을 때 어떤 데이터를 방출할 것인가. LRU, LFU, FIFO 등

### 2-7. CDN : 넓은 사용자 분포

Content Delivery Network. 정적 콘텐츠(이미지, html 등)를 가까운 서버에 캐싱.

동적 콘텐츠 캐싱도 있다.

고려사항

- 비용 : 콘텐츠 전송량으로 요금이 부과되어 자주 사용되지 않는 데이터는 제거
- 만료 기한 : 길면 콘텐츠 신선도가 떨어지고, 짧으면 원본 서버 조회가 잦아진다.
- 장애 대처 : CDN 이 죽었을 때 원본 서버를 조회하도록 클라이언트 구현 필요
- 콘텐츠 invalidation : 만료되지 않은 컨텐츠를 제거하는 방법

### 2-8. stateless 웹 계층

세션 등 상태 의존적 데이터를 공유 저장소에 유지하고, 서버는 stateless 하게 처리

요청을 받은 서버가 요청을 한 클라이언트에게 데이터를 돌려주기 위해 발생하는 대기 등의 비용을 줄인다.

### 2-9. 데이터 센터 : 국제적 사용자 발생

물리적으로 다른 지역에 웹 서버 + 데이터베이스 + 캐시를 묶어 구성한다.

이 때 데이터 센터 선택을 위해 geo-routing 을 사용한다.

물론, 한 데이터 센터가 죽으면 가까운 다른 센터에서 서비스한다.

고려사항

- 트래픽 우회 : 가까운 데이터 센터 선택 방법. 보통 GeoDNS
- 데이터 동기화 : 데이터 센터 간 동기화
- 테스트와 배포 : 데이터 센터가 다르면 보통 환경이 다르다. 각 환경에 맞는 테스트와 자동 배포가 필요

### 2-10. 메시지 큐

트래픽 처리 서버와 별개로 미디어 서버와 같이 별개의 작업을 수행하는 서버를 따로 구성하고,

웹 서버가 작업 서버에 비동기 요청을 보내기 위해 메시지 큐를 중간에 둔다.

### 2-11. 로그, 메트릭, 자동화

이제는 지속적인 운영을 위해 에러 로그와 CPU, 메모리 등의 메트릭 정보 모니터링이 필요하다.

CI/CD를 위해 빌드, 테스트, 배포 절차 자동화도 필요하다.

### 2-12. 데이터베이스 확장

데이터베이스도 스케일 업은 비용이 비싸고, failover 대응이 어렵다.

스케일 아웃을 위해 샤딩이 적용된다. 하나의 데이터 셋을 중복되지 않게 나누어 분산 노드에 저장.

고려사항

- 재샤딩 : shard exhaustion이 발생했을 때 데이터를 어떻게 재배치할까. 보통 안정 해시 사용
- celebrity 문제 : 특정 샤드에 질의가 집중되어 과부하가 걸리는 경우.
- 조인과 비정규화 : 샤드로 데이터를 쪼개면 join하기 어려워 애초에 데이터를 비정규화 해야한다.

### 2-13. 그 이상 : 백만 사용자 이상

시스템 최적화, 서비스를 더 작은 단위로 분할 등등

# 2장. 개략적인 규모 추정

## 1. 응답 지연 값

| 연산 | 시간 |
| --- | --- |
| L1 캐시 참조 | 0.5ns |
| 분기 예측 오류 | 5ns |
| L2 캐시 참조 | 7ns |
| mutex 락/언락 | 100ns |
| 주 메모리 참조 | 100ns |
| zippy 1kb 압축 | 10μs |
| 네트워크 2kb 전송(1Gbps) | 20μs |
| 메모리 1MB 읽기 | 250μs |
| 데이터 센터 내 메시지 왕복 | 500μs |
| 디스크 탐색 | 10ms |
| 네트워크 1mb 읽기 | 10ms |
| 디스크 1mb 읽기 | 30ms |
| 네트워크 패킷 지구 한바퀴 | 150ms |

알 수 있는 것

- L1 캐시 참조 : 캐시는 여전히 엄청 빠르다
- 주 메모리 참조 : RAM은 하드디스크와는 비교가 불가하다
- zippy : 기본적인 압축은 생각보다 빠르다. 네트워크는 압축을 하는 것이 기본이다.
- 네트워크 패킷 지구 한 바퀴 : 지역별 데이터 센터는 필수적이다.

## 2. 가용성 수치

| 가용률 | 연간 장애 시간 |
| --- | --- |
| 99% | 3.65일 |
| 99.9% | 8.77시간 |
| 99.99% | 52.60분 |
| 99.999% | 5.26분 |
| 99.9999% | 31.56초 |

## 3. QPS 측정

QPS : Query Per Seconds = 사용자 * 사용율 * 평균 질의 수 * 용량(미디어, 텍스트 구분) * 데이터 저장 기간
